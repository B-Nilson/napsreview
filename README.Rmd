---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# napsreview

<!-- badges: start -->
<!-- badges: end -->

`napsreview` is an R package with the goal of assessing the validity of the National Air Pollution Surveillance (NAPS) Program archive of Canadian quality-assured continuous air quality observations.

You can read more about the NAPS Program [here](https://open.canada.ca/data/en/dataset/1b36a356-defd-4813-acea-47bc3abd859b).

There are two key parts to `napsreview`: 

1. Creation of a local database of NAPS (and comparison) data (see [Build database](#build-database))
2. Validity assessment of NAPS data (see [Assess validity](#assess-validity))

## Installation

Using R, you can install the development version of napsreview from [GitHub](https://github.com/) with:

``` r
# install.packages("pak")
pak::pak("B-Nilson/napsreview")
```

# Build database

The NAPS dataset is split into annual files by pollutant. 
Below we download each of those files and dump them into a `duckdb` database, 
as well as format and combine them into a single dataset.

We also want to compare with another source for the same dataset
to check timestamp alignment, so we download and archive data 
from the BC Government for the same time period as the NAPS data collected. 

```{r collect_data, eval = FALSE}
library(napsreview)
desired_years <- 1974:2023
desired_pollutants <- c("PM25", "O3", "NO2")

# Define local paths (default is the install dir of napsreview)
#  but you can change that if needed
raw_data_dir <- "extdata/naps_raw" |>
  system.file(package = "napsreview")
db_path <- "extdata" |>
  system.file(package = "napsreview") |>
  file.path("naps.duckdb")

# Create (if needed) and connect to local database
db <- connect_to_database(db_path)
on.exit(DBI::dbDisconnect(db))

# Collect data for desired years/pollutants
naps_data <- desired_years |>
  get_naps_data(
    pollutants = desired_pollutants,
    raw_data_dir = raw_data_dir,
    check_if_raw_exists = TRUE # don't download if already exists locally
  )

# Write raw data to database if needed
if (!DBI::dbExistsTable(db, "raw_data")) {
  db |>
    archive_raw_naps_data(
      naps_data = naps_data,
      raw_data_tbl = "raw_data",
      raw_headers_tbl = "raw_data_headers"
    )
}

# Format data and write to database if needed
if (!DBI::dbExistsTable(db, "fmt_data")) {
  db |>
    archive_fmt_naps_data(
      naps_data = naps_data,
      fmt_data_tbl = "fmt_data",
      fmt_meta_tbl = "fmt_meta"
    )
}

# Get and archive bcgov data if needed
if (!DBI::dbExistsTable(db, "bcgov_data")) {
  date_range <- db |>
    dplyr::tbl("raw_data") |>
    dplyr::select(date = `Date//Date`) |>
    dplyr::summarise(
      min_date = min(date, na.rm = TRUE),
      max_date = max(date, na.rm = TRUE)
    ) |>
    dplyr::collect()
  date_range <- c(date_range$min_date, date_range$max_date)
  db |>
    get_and_archive_bcgov_data(date_range = date_range)
}

```

And you can check that worked and view the data using the following:

```{r check_data, eval = FALSE}
library(napsreview)

# Connect to database (change path here if you did earlier as well)
db_path <- system.file("extdata", package = "napsreview") |>
  file.path("naps.duckdb")
db <- connect_to_database(db_path)
on.exit(DBI::dbDisconnect(db))

# Print the first 10 rows of each table
#   Note - these are lazy tables.
#   You need to pass to dplyr::collect() if
#   you want to query and load the data from the database
db |> dplyr::tbl("raw_data")
db |> dplyr::tbl("raw_data_headers")
db |> dplyr::tbl("fmt_data")
db |> dplyr::tbl("fmt_meta")
db |> dplyr::tbl("bcgov_data")


```

# Assess Validity

Several relatively minor issues have been found in the NAPS dataset:

* A major format change occurred around 2004 (see [Data Format Differences](#data-format-differences)).
* Site meta data values are inconsistent between files (see [Inconsistent Metadata](#inconsistent-metadata)).
* Some coordinate and concentration values are unrealistic (see [Unrealistic Values](#unrealistic-values)).

However, most noteably an inconsistent date mis-aligment was discovered for several sites/years (see [Date Misalignment](#date-misalignment)).


## Data Format Differences

The NAPS data format changed after 2004 to include French and English headers and several other format changes. Strangley, the 2002 files for NO2 and O3 use the new format, unlike the rest of the files for those pollutants prior to 2005.

Noteably:

* new files are encoded in UTF-8, old files are latin1
* new files have FR and EN headers (i.e. 'City//Ville' instead of 'City')
* new files have slightly different pre-data header format
* new files have a different date format (i.e. "2025-01-01" instead of "20040101")

```{r format_shift, eval = FALSE}
library(napsreview)

# Connect to database (change path here if you did earlier as well)
db_path <- system.file("extdata", package = "napsreview") |>
  file.path("naps.duckdb")
db <- connect_to_database(db_path)
on.exit(DBI::dbDisconnect(db))

# View encoding differences between versions (change path here if you did earlier as well)
raw_data_dir <- "extdata/naps_raw" |>
  system.file(package = "napsreview")
raw_data_dir |>
  file.path("PM25_2002.csv") |> # v1 file
  readLines(encoding = "UTF-8") |> # actually latin1
  stringr::str_subset("\xb5") |> # so non-standard characters are broken
  head()
raw_data_dir |>
  file.path("PM25_2006.csv") |> # same file
  readLines(encoding = "latin1") |> # now we try latin1
  stringr::str_subset("\xb5") |> # so nothing broken
  head()
raw_data_dir |>
  file.path("PM25_2006.csv") |> # v2 file
  readLines(encoding = "UTF-8") |> # UTF-8 as expected
  stringr::str_subset("\xb5") |> # so nothing broken
  head()

# View file differences between versions
# Note: name and row_number are added by `napsreview` to ensure uniqueness in the db
# Note: 'Method' / 'Method Code//Code MÃ©thode' are included for non-PM25 pollutants for consistency, even though they are not found in the raw files
db |> dplyr::tbl("raw_data_v1")
db |> dplyr::tbl("raw_data_v2")

# View pre-data header differences between versions
db |> dplyr::tbl("raw_data_headers_v1")
db |> dplyr::tbl("raw_data_headers_v2")

# View date format differences between versions
db |>
  dplyr::tbl("raw_data_v1") |>
  head(n = 1) |>
  dplyr::pull("Date") |>
  as.character()
db |>
  dplyr::tbl("raw_data_v2") |>
  head(n = 1) |>
  dplyr::pull("Date//Date") |>
  as.character()
```

These files have been identified as having the old format:

```{r format_shift_summary, eval = TRUE, echo = FALSE}
library(napsreview)

"extdata/issues/old_format_files.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tidyr::separate(file_name, into = c("pollutant", "year"), sep = "_") |>
  dplyr::group_by(pollutant) |>
  dplyr::summarise(years = sentence_range(as.integer(year))) |>
  tidyr::unite(col = "text", pollutant, years, sep = ": ") |>
  dplyr::pull(text) |>
  paste(collapse = "\n") |>
  cat()
```

## Inconsistent Metadata

Every entry in the raw NAPS data has latitude, longitude, province/territory, and city information.
However, for many sites these values are inconsistent between files.

For example, lat/lng values have differing precisions between files causing slight shifts in location.

```{r inconsistent_coords, eval = TRUE, echo = FALSE}
"extdata/issues/multiple_loc_sites.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::mutate(dplyr::across(c(lat, lng), as.character))
```

In addition, city names are inconsistently spelled between files

```{r inconsistent_city_spelling, eval = TRUE, echo = FALSE}
"extdata/issues/multiple_city_spellings.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble()
```

and some sites have multiple city names across files.

```{r inconsistent_site_city, eval = TRUE, echo = FALSE}
"extdata/issues/multiple_city_sites.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble()
```

## Invalid Metadata

Throughout the files, the Yukon territory is marked with the old abbreviation "YK", the official abbreviation is now "YT" and should be used.
(see [here](https://www.noslangues-ourlanguages.gc.ca/en/writing-tips-plus/abbreviations-canadian-provinces-and-territories))

```{r unofficial_pt, eval = TRUE, echo = FALSE}
"extdata/issues/non_official_provinces.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::filter(original != official)
```

For some sites/files, the coordinates are outside of the province/territory they are marked to be in - for some it appears to be a typo or rounding issue, but for a few it is a complely invalid longitude.

```{r invalid_coords, eval = TRUE, echo = FALSE}
"extdata/issues/out_of_province_coords.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::mutate(
    dplyr::across(c(lat, lng), as.character),
    expected_prov_terr = expected_prov_terr |> handyr::swap("", with = NA)
  ) |>
  dplyr::arrange(expected_prov_terr, prov_terr)
```

## Unrealistic Values

Some values in the raw data are unrealistically high or low, coordinates exist that are outside Canada, and some site ids are not properly padded with leading zeros.

Here is a sample of files/sites with negative concentrations:
```{r negatives, eval = TRUE, echo = FALSE}
"extdata/issues/invalid_values.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::filter(has_negatives) |>
  dplyr::select(file_name, site_ids)
```

Here is a sample of files/sites with concentrations above 2000:
```{r extremes, eval = TRUE, echo = FALSE}
"extdata/issues/invalid_values.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::filter(has_values_above_2000) |>
  dplyr::select(file_name, site_ids)
```

Here is a sample of files/sites with invalid site ids:
```{r unrealistic_id, eval = TRUE, echo = FALSE}
"extdata/issues/invalid_values.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::filter(has_bad_site_id) |>
  dplyr::select(file_name, site_ids)
```

## Date Misalignment

Inconsistencies have been found in the hourly alignment of NAPS data for some sites in entirety, and for select years for some sites, when compared to the same station's data sourced directly from the BC Government archive. Due to NAPS recieving their data from BC, this issue is likely due to an error in how the NAPS data are converted to local hour and archived.

Given the presence of the BC Government archive with clear documentation on data timezone, a standardized data format, and the ability to collect data programmatically, this issue has only been assessed for BC. However, it is likely that this issue affects data from across the country.

Below we load in the BCgov/NAPS data alligned by naps_id and date, 
and test the correlation between the two datasets for each pollutant at various time lags.
Given that these datasets should be essentially the same, the correlation should be near perfect (small differences could occure due to rounding or differing QAQC decisions). 
Sites years where the correlation goes from poor to near perfect after lagging the data have allignment issues. 

```{r date_misalignment, eval = FALSE}
library(napsreview)

# Connect to database (change path here if you did earlier as well)
db_path <- system.file("extdata", package = "napsreview") |>
  file.path("naps.duckdb")
db <- connect_to_database(db_path)
on.exit(DBI::dbDisconnect(db))

# View the bcgov/naps data aligned by naps_id and date
db |> dplyr::tbl("bcgov_aligned_data")

# Load the aligned data
aligned_data <- db |>
  dplyr::tbl("bcgov_aligned_data") |>
  dplyr::collect() |>
  # Censor negative values, round to nearest integer (NAPS data are integers)
  dplyr::mutate(
    dplyr::across(dplyr::ends_with(c("_naps", "_bcgov")), \(x) {
      ifelse(x < 0, NA_real_, x) |> round(digits = 0)
    })
  )

# Test alignment for each pollutant
passed <- list()
pollutants <- names(aligned_data) |>
  stringr::str_subset("_bcgov$") |>
  sub(pattern = "_bcgov$", replacement = "")
issues_dir <- paste0("extdata/issues") |> # adjust as needed
  system.file(package = "napsreview")
for (pollutant in pollutants) {
  passed[[pollutant]] <- aligned_data |>
    check_date_alignment(
      pollutant = pollutant,
      value_cols = pollutant |> paste0("_", c("bcgov", "naps")),
      name_cols = pollutant |> paste0("_", c("bcgov_lag", "naps_lag")),
      save_issues_to = issues_dir
    )
}

```

Here is a sample of the sites with persistent date misalignment issues (PM2.5 only, but they exist for other pollutants - see [here](extdata/issues/)). "_lag_1" indicates that those data are lagged by 1 hour (i.e. those data are incorrectly shifted 1 hour later). Here all of the sites go from 70-90% correlation to 93-100% after lagging the NAPS data by 1 hour.

```{r site_alignment, eval = TRUE, echo = FALSE}
"extdata/issues/pm25_site_alignment.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::select(-X) # TODO: don't write out row names
```

Here is a sample of the sites with date misalignment issues for specific years (PM2.5 only, but they exist for other pollutants). Here all of the sites go from 70-90% correlation to 93-100% after lagging the NAPS data by 1 hour.

```{r annual_site_alignment, eval = TRUE, echo = FALSE}
"extdata/issues/pm25_annual_site_alignment.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::select(-X) # TODO: don't write out row names
```

And this becomes quite clear when looking at the monthly correlation between the two datasets. Here is two samples of that, see [monthly_cor_plots](/inst/extdata/issues/monthly_cor_plots) for the full set.

![](/inst/extdata/issues/monthly_cor_plots/100110_pm25_bcgov_pm25_naps.png)
![](/inst/extdata/issues/monthly_cor_plots/100112_no2_bcgov_no2_naps.png)
![](/inst/extdata/issues/monthly_cor_plots/105504_o3_bcgov_o3_naps.png)

By mapping the locations of sites with allignment issues, we can see that the sites are all either in the metro-vancouver / lower fraser valley region, or east of the Rockies (where DST is not observed, and MT is in place instead of PT). The exception is Quesnel, however that site has a longitude issue that places it in Alberta for some years. 

```{r quesnel_issue, eval = TRUE, echo = FALSE}
"extdata/naps_meta.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  dplyr::filter(site_id == 101701) |>
  tibble::as_tibble()
```

The "east of the Rockies" issue further supports the hypothesis that the date misalignment occurs in the conversion to local hour when archiving the NAPS data. For the Vancouver area monitors the reason is less clear, but could be due to how air quality is managed in that region seperatley from the rest of the province.

```{r misalignment_map, eval = TRUE, echo = FALSE, cache = TRUE}

bad_sites <- "extdata/issues/pm25_annual_site_alignment.csv" |>
  system.file(package = "napsreview") |>
  read.csv() |>
  tibble::as_tibble() |>
  dplyr::distinct(naps_id) |>
  dplyr::left_join(
    "extdata/naps_meta.csv" |>
      system.file(package = "napsreview") |>
      read.csv() |>
      dplyr::group_by(site_id, city) |>
      dplyr::summarise(
        dplyr::across(c(lat, lng), median),
        .groups = "drop"
      ) |>
      dplyr::distinct(site_id, .keep_all = TRUE),
    by = c("naps_id" = "site_id")
  ) |>
  sf::st_as_sf(coords = c("lng", "lat"), crs = "WGS84")

point_layers <- list(
  aqmapr::PointLayer(
    group = "NAPS sites",
    data = bad_sites,
    fill = "#ff5e00",
    label = ~ paste0(naps_id, ": ", city)
  )
)
# May need to run: webshot::install_phantomjs()
aqmapr::make_leaflet_map(
  point_layers = point_layers,
  track_map_state = FALSE
) |>
  mapview::mapshot(file = "inst/extdata/issues/misalignment_map.png")

```

![](/inst/extdata/issues/misalignment_map.png)
